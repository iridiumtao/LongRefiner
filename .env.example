# Select the backend for LongRefiner.
# Supported values:
# "hf"   - Use the Hugging Face Transformers backend. Works on Apple Silicon (MPS), CPU, and NVIDIA GPUs. Recommended for local development.
# "vllm" - Use the high-performance vLLM backend. Requires an NVIDIA GPU with CUDA. Recommended for production/HPC.
#
# If this variable is not set, the system will attempt to auto-detect the best backend.
LONGREFINER_BACKEND="vllm"